{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词器的获取\n",
    "Unsurprisingly, there are many more techniques out there. To name a few:\n",
    "\n",
    "Byte-level BPE, as used in GPT-2\n",
    "\n",
    "WordPiece, as used in BERT\n",
    "\n",
    "SentencePiece or Unigram, as used in several multilingual models\n",
    "\n",
    "You should now have sufficient knowledge of how tokenizers work to get started with the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n",
      "          2607,  2026,  2878,  2166,  1012,   102],\n",
      "        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0],\n",
      "        [  101,  1045,  2293,  2014,   102,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "[CLS] i've been waiting for a huggingface course my whole life. [SEP]\n",
      "[CLS] i hate this so much! [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n",
      "[CLS] i love her [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "    \"I love her\"\n",
    "]\n",
    "# 默认返回的是list格式，而不是tensor格式\n",
    "inputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print(inputs)\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))\n",
    "print(tokenizer.decode(inputs['input_ids'][1]))\n",
    "print(tokenizer.decode(inputs['input_ids'][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对于2个句子，tokenizer处理方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] i've been waiting for a huggingface course my whole life. [SEP] i hate this so much! [SEP]\n",
      "[CLS] i've been waiting for a huggingface course my whole life. [SEP] i've been waiting for a huggingface course my whole life. [SEP]\n"
     ]
    }
   ],
   "source": [
    "inputs=tokenizer( \"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\")\n",
    "print(tokenizer.decode(inputs['input_ids']))\n",
    "\n",
    "\n",
    "# sentence1->list sentence2->list\n",
    "inputs=tokenizer( [\"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\"],[\"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\"])\n",
    "\n",
    "print(tokenizer.decode(inputs['input_ids'][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102, 1045, 5223, 2023, 2061, 2172, 999, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#切换另外一个tokenizer\n",
    "bert_tokz=AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "inputs=bert_tokz( \"I've been waiting for a HuggingFace course my whole life.\",\"I hate this so much!\")\n",
    "inputs\n",
    "# token_type_ids表示是第一个句子，还是第二个句子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获得模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 16, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DistilBertModel(\n",
       "  (embeddings): Embeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x TransformerBlock(\n",
       "        (attention): MultiHeadSelfAttention(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (ffn): FFN(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=AutoModel.from_pretrained(checkpoint)\n",
    "# model=AutoModel.from_pretrained(checkpoint,num_labels=33,ignore_mismatched_sizes=True)\n",
    "\n",
    "outputs=model(**inputs)\n",
    "print(outputs.last_hidden_state.shape)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer=model.get_submodule(\"transformer.layer.5.output_layer_norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于分类的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
    "# outputs=model(**inputs)\n",
    "# outputs = model(**inputs)\n",
    "# print(outputs.logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用于生成的的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel,AutoConfig\n",
    "from fastbook import *\n",
    "import fastbook\n",
    "\n",
    "fastbook.setup_book()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the config\n",
    "# config = AutoConfig.from_pretrained(\"bert-base-cased\",hidden_dropout_prob=0.3)\n",
    "# 如果指定具体的类型，可以指定，这里覆盖了默认的参数\n",
    "config = BertConfig.from_pretrained(\"bert-base-cased\",hidden_dropout_prob=0.3)\n",
    "\n",
    "# 有了config就可以创建具体的模型了\n",
    "model = BertModel(config)\n",
    "# 当然，还是使用与训练的更好\n",
    "# model=BertModel.from_pretrained('bert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.3,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.23.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.3, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存，读取与训练模型\n",
    "model.save_pretrained('a/my')\n",
    "AutoModel.from_pretrained('a/my')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ed71b527504255a5136d12982e24ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# glue是由10多种数据集构成的benckmark\n",
    "#mrpc是数据集，比较2句话是否是一个意思\n",
    "#  ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'mnli_mismatched', 'mnli_matched', 'qnli', 'rte', 'wnli', 'ax']\n",
    "raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': ['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .'],\n",
       " 'sentence2': ['Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'],\n",
       " 'label': [1],\n",
       " 'idx': [0]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#可以按行访问\n",
    "raw_datasets['train'][0:1]\n",
    "# 也可以按列访问\n",
    "# raw_datasets['train']['sentence1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(num_classes=2, names=['not_equivalent', 'equivalent'], id=None),\n",
       " 'idx': Value(dtype='int32', id=None)}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8a079cdcc14c8ebaff968f0da3da4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3592bad16bc4f95b93df4205b898a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f40582028b4effa26abe730c3c2c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizr_func(example):\n",
    "    # 把sentence1,sentence2连到一起进行 数值化处理，返回的格式是list\n",
    "    return tokenizer(example['sentence1'],example['sentence2'],padding=True,truncation=True,max_length=128)\n",
    "\n",
    "# 批量数值化原始数据集\n",
    "ds=raw_datasets.map(tokenizr_func,batched=True)\n",
    "# 移除多余的列， 重命名目标\n",
    "ds=ds.remove_columns(['sentence1','sentence2','idx']).rename_column('label','labels')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 2751\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 917\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['train'].train_test_split(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 3668\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 408\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "        num_rows: 1725\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 动态与静态padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import dataset, sampler, dataloader\n",
    "import torch\n",
    "\n",
    "def padding_fix(example,maxlen=512):\n",
    "    ret= tokenizer(example['sentence1'],example['sentence2'],padding=True,truncation=True,max_length=maxlen)\n",
    "    return ret\n",
    "def padding_dynamic(example,maxlen=512):\n",
    "    ret= tokenizer(example['sentence1'],example['sentence2'])\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n",
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n",
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n",
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n",
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n",
      "torch.Size([5, 89]) torch.Size([5, 89]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "ds_train=raw_datasets['train'].map(padding_fix,batched=True)\n",
    "ds_train=ds_train.remove_columns(['sentence1','sentence2','idx']).rename_column('label','labels')\n",
    "\n",
    "# dataset.map返回的数据集，sample是存放在list中的，加上这句话，把list转换成对应的tensor\n",
    "ds_train=ds_train.with_format('torch')\n",
    "\n",
    "#可以看到，如果使用padding_fix，所有的样本都会被padding成最长的\n",
    "dls=dataloader.DataLoader(ds_train,batch_size=5,shuffle=False)\n",
    "for k,t in enumerate(dls):\n",
    "    print(t['input_ids'].shape,t['attention_mask'].shape,t['labels'].shape)\n",
    "    if k==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fb3540837a4f6fa0cd5e476bbd6bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 67]) torch.Size([5, 67]) torch.Size([5])\n",
      "torch.Size([5, 62]) torch.Size([5, 62]) torch.Size([5])\n",
      "torch.Size([5, 61]) torch.Size([5, 61]) torch.Size([5])\n",
      "torch.Size([5, 79]) torch.Size([5, 79]) torch.Size([5])\n",
      "torch.Size([5, 64]) torch.Size([5, 64]) torch.Size([5])\n",
      "torch.Size([5, 68]) torch.Size([5, 68]) torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "ds_train=raw_datasets['train'].map(padding_dynamic,batched=True)\n",
    "ds_train=ds_train.remove_columns(['sentence1','sentence2','idx']).rename_column('label','labels')\n",
    "# dataset.map返回的数据集，sample是存放在list中的，加上这句话，把list转换成对应的tensor\n",
    "ds_train=ds_train.with_format('torch')\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "dls=dataloader.DataLoader(ds_train,batch_size=5,shuffle=False,collate_fn=data_collator)\n",
    "\n",
    "#可以看到，如果使用padding_dynamic，每个batch会被 padding成batch中最长的长度\n",
    "for k,t in enumerate(dls):\n",
    "    print(t['input_ids'].shape,t['attention_mask'].shape,t['labels'].shape)\n",
    "    if k==5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11]) torch.Size([11, 68])\n"
     ]
    }
   ],
   "source": [
    "# data_collator接受一个map，都没个把每个value(list)都转换成对于的tensor,如果value的元素长度参差不齐时，使用padding补齐后，在转成tensor\n",
    "batch=data_collator(ds_train[20:31])\n",
    "print(batch['labels'].shape,batch['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1,  ..., 1, 1, 0])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk=33\n",
    "# tokenizer.convert_ids_to_tokens(ds_train['input_ids'][kk]),len(ds_train['input_ids'][kk])\n",
    "# torch.tensor(ds_train['input_ids'][22:55]).shape\n",
    "# ds_train['attention_mask'][22:25]\n",
    "len(ds_train['input_ids']),ds_train['input_ids'][100].shape\n",
    "ds_train['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 从pandas获得dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,DatasetDict\n",
    "import pandas\n",
    "df=pandas.read_csv('a.csv')\n",
    "\n",
    "ds = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer,TrainingArguments,DataCollatorWithPadding\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-4f16cc51848abc4a.arrow\n",
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-5e14ebdb0725d9fa.arrow\n",
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-988406d9e4008365.arrow\n"
     ]
    }
   ],
   "source": [
    "def custom_token_fn(example):\n",
    "    return tokenizer(example['sentence1'],example['sentence2'],truncation=True)\n",
    "token_ds=raw_datasets.map(custom_token_fn,batched=True)\n",
    "token_ds=token_ds.remove_columns(['sentence1','sentence2','idx']).rename_column('label','labels')\n",
    "token_ds=token_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "loading configuration file config.json from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\3d65bad49c7ba6f71920504507a8927f4b9db6c0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.23.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\3d65bad49c7ba6f71920504507a8927f4b9db6c0\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# evaluation_strategy 在测试集上测试 的时间间隔策略\n",
    "#learning_rate\n",
    "#per_device_train_batch_size\n",
    "#per_device_eval_batch_size\n",
    "#num_train_epochs\n",
    "#weight_decay\n",
    "\n",
    "# warmup_ratio:  ??\n",
    "# lr_scheduler_type: ??\n",
    "\n",
    "args=TrainingArguments('output',evaluation_strategy='epoch')\n",
    "def compute_metrics(data):\n",
    "    logits,labels=data\n",
    "    \n",
    "    pred_labels=np.argmax(logits,-1)\n",
    "    acc=(pred_labels==labels).mean()\n",
    "    \n",
    "    return {\"acc\":acc}\n",
    "\n",
    "def compute_metrics_mrpc(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    #这是evaluate返回函数的固定方法compute,根据预测与标注，返回dict（包含所有指标）\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(model,args,\n",
    "                train_dataset=token_ds['train'],\n",
    "                eval_dataset=token_ds['validation'],\n",
    "                data_collator=DataCollatorWithPadding(tokenizer),\n",
    "                tokenizer=tokenizer,\n",
    "                compute_metrics=compute_metrics\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3668\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1377' max='1377' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1377/1377 10:24, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.402058</td>\n",
       "      <td>0.838235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.507300</td>\n",
       "      <td>0.483808</td>\n",
       "      <td>0.840686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.722676</td>\n",
       "      <td>0.840686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output\\checkpoint-500\n",
      "Configuration saved in output\\checkpoint-500\\config.json\n",
      "Model weights saved in output\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-500\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to output\\checkpoint-1000\n",
      "Configuration saved in output\\checkpoint-1000\\config.json\n",
      "Model weights saved in output\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in output\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in output\\checkpoint-1000\\special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 408\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1377, training_loss=0.3287302403668173, metrics={'train_runtime': 625.4079, 'train_samples_per_second': 17.595, 'train_steps_per_second': 2.202, 'total_flos': 204499651379856.0, 'train_loss': 0.3287302403668173, 'epoch': 3.0})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1725\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((1725, 2),\n",
       " (1725,),\n",
       " {'test_loss': 0.8396176099777222,\n",
       "  'test_acc': 0.8191304347826087,\n",
       "  'test_runtime': 22.1269,\n",
       "  'test_samples_per_second': 77.959,\n",
       "  'test_steps_per_second': 9.762})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### test dataset\n",
    "test_predict=trainer.predict(token_ds['test'])\n",
    "test_predict.predictions.shape,test_predict.label_ids.shape,test_predict.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 与pytorch 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "DEVICE='cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-aef651eabbc0fe31.arrow\n",
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-d98532cb24e169be.arrow\n",
      "Loading cached processed dataset at C:/Users/Administrator/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-554ae6d17f8981ec.arrow\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorWithPadding\n",
    "#数据集准备\n",
    "def custom_token_fn(example):\n",
    "    return tokenizer(example['sentence1'],example['sentence2'],truncation=True)\n",
    "token_ds=raw_datasets.map(custom_token_fn,batched=True)\n",
    "token_ds=token_ds.remove_columns(['sentence1','sentence2','idx']).rename_column('label','labels')\n",
    "token_ds=token_ds.with_format('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(token_ds['train'],batch_size=16,shuffle=True,collate_fn=DataCollatorWithPadding(tokenizer))\n",
    "val_loader=DataLoader(token_ds['validation'],batch_size=16,shuffle=True,collate_fn=DataCollatorWithPadding(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\3d65bad49c7ba6f71920504507a8927f4b9db6c0\\config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"finetuning_task\": \"sst-2\",\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"NEGATIVE\",\n",
      "    \"1\": \"POSITIVE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"NEGATIVE\": 0,\n",
      "    \"POSITIVE\": 1\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.23.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at C:\\Users\\Administrator/.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english\\snapshots\\3d65bad49c7ba6f71920504507a8927f4b9db6c0\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "\n",
    "model=AutoModelForSequenceClassification.from_pretrained(checkpoint,num_labels=2).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39663461538461536"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_accuracy(dls):\n",
    "    accuracy=[]\n",
    "    model.eval()\n",
    "    for batch in dls:\n",
    "        b={k:v.to(DEVICE) for k,v in batch.items()}\n",
    "        logits=model(**b).logits\n",
    "        pred_labels=logits.argmax(-1)\n",
    "        accuracy.append((b['labels']==pred_labels).float().mean().item())\n",
    "    model.train()\n",
    "    return np.mean(accuracy)\n",
    "evaluate_accuracy(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ae25a94b444b1485b8626e38880a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/690 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4014423076923077\n",
      "0.4110576923076923\n",
      "0.4855769230769231\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import get_scheduler\n",
    "\n",
    "\n",
    "\n",
    "epoch=3\n",
    "steps=epoch*len(train_loader)\n",
    "\n",
    "progress=tqdm(range(steps))\n",
    "# get_submodule('classifier')\n",
    "optimizer=torch.optim.AdamW(model.get_submodule('classifier').parameters(),5e-5)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=steps,\n",
    ")\n",
    "\n",
    "ce=torch.nn.functional.cross_entropy\n",
    "model.train()\n",
    "for _ in range(epoch):\n",
    "    print(evaluate_accuracy(val_loader))\n",
    "    for batch in train_loader:\n",
    "        b={k:v.to(DEVICE) for k,v in batch.items()}\n",
    "        logits=model(**b).logits\n",
    "        loss=ce(logits,b['labels'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        progress.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8317307692307693"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "366.974px",
    "width": "231.974px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
