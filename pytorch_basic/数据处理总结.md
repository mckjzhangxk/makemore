# 迭代器定义
```python
generator=(1 for x in range(3))
for i in generator:
    print(i)
mylist=[1 for x in range(3)]

```
# DataSet对象
```python
from torch.utils.data import dataset, sampler, dataloader

class MyDataSet(dataset.Dataset):
    def __init__(self) :
        self.data=list(range(1,100))
    def __len__(self):
        return len(self.data)
    def __getitem__(self, index):
        return self.data[index]
```
* 一般在init函数指定数据源，加载好数据
* len数据是数据集的长度，如果不知道，DataLoader就无法知道数据集的长度。
* getitem 的index应该理解为key,Dataset可以理解成一个map,**getitem是根据key返回value的函数**。


# DataLoader对象
```python
from torch.utils.data import dataset, sampler, dataloader

data_loader=dataloader.DataLoader(
    MyDataSet(),
    batch_size=10,
    shuffle=False,
    drop_last=False,
)

for i,batch_data in enumerate(data_loader):
    print(batch_data[:],len(batch_data))
```
* DataLoader的作用是批量返回Dateset的数据， 迭代一个data_loader,会触发batch_size调用Dateset的getitem方法。
* batch_data的类型是tuple,长度是batch_size。
* 在调用dataset.getitem的时候， 使用的key是int类型，如果dataset的key是其他类型，需要传递**sampler自定义采样器**。
* shuffle是对key是int类型的数据集就行 随机打乱的，不可与sampler同时设置。

# Sampler对象
```python
class MySampler(sampler.Sampler):
    def __init__(self):
        pass
    # def __len__(self):
    #     return 2
    def __iter__(self):
        return iter([0]*51)

data_loader=dataloader.DataLoader(
    MyDataSet(),
    batch_size=10,
    shuffle=False,
    drop_last=False,
    sampler=MySampler()
)

for i,batch_data in enumerate(data_loader):
    print(batch_data[:],len(batch_data))
```
* sampler设置如何从Dataset获取value,iter方法返回迭代器，迭代器的长度决定
data_loader的迭代次数。

* 迭代器每次调用要返回一个key,**这个key的类型要与Dataset.getitem的key类型兼容**。


# 非int类型key的数据集
```python
from torch.utils.data import dataset, sampler, dataloader

class MyDataSet(dataset.Dataset):
    def __init__(self) :
        self.names=list(range(1,100))
    def __getitem__(self, key):
        v=[self.data[index] for index in key]
        return v

class MySampler(sampler.Sampler):
    def __init__(self):
        pass
    def __iter__(self):
        return iter([(0,1,1),(2,3)])

data_loader=dataloader.DataLoader(
    MyDataSet(),
    batch_size=10,
    shuffle=False,
    drop_last=False,
    sampler=MySampler(),
    collate_fn=lambda x:x
)

for i,batch_data in enumerate(data_loader):
    print(i,batch_data,f"size={len(batch_data)}")
>> 输出:
>> 0 [[1, 2, 2], [3, 4]] size=2
```

* MyDataSet key=tutle(),value=key中索引对于的值
* MySampler 的迭代器返回2个key,分别是(0,1,1)和（2,3)
* collate_fn是整理函数，输入是 MyDataset的value,这里选择原样返回！
